{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "500d2ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce74ca07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5d165bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"]=os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa0ae65",
   "metadata": {},
   "source": [
    "# Example 1: simple LLM call with streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "157d5ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage,SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c1c568a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000286F60C63C0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000286F5CDB500>, model_name='deepseek-r1-distill-llama-70b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=init_chat_model(\"groq:deepseek-r1-distill-llama-70b\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee9126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another method to create model\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5be7c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create massages\n",
    "messages=[\n",
    "    SystemMessage(\"You are helpful AI assistant \"),\n",
    "    HumanMessage(\"What are the use and benefits of Langchain\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eed5fb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, so I\\'m trying to understand what LangChain is and why it\\'s useful. I\\'ve heard it mentioned in the context of AI and programming, but I\\'m not entirely sure what it does. Let me start by breaking down the name: \"Lang\" probably refers to language, and \"Chain\" might imply some sort of linking or sequencing. Maybe it\\'s a tool that connects different language models or helps in processing language in a sequential way?\\n\\nI remember that language models like GPT can process and generate text, but sometimes they need to handle more complex tasks that require multiple steps or interactions with external data. So perhaps LangChain is a framework that allows developers to chain together different models or functions to create more sophisticated applications. That would make sense because sometimes a single model isn\\'t enough for intricate tasks.\\n\\nLooking at the use cases mentioned earlier: AI assistants, chatbots, document processing, code generation, creative writing, and research. It seems LangChain is versatile. For example, in AI assistants, it might help structure the assistant\\'s responses by breaking down tasks into manageable steps. In document processing, maybe it extracts information and then summarizes it, which would require multiple operations.\\n\\nI\\'m a bit confused about how exactly LangChain integrates with external data sources and APIs. Does it act as a middleware that connects different services, or is it more about orchestrating the flow of data between them? Also, how does it handle memory? If it\\'s using a memory module, does that mean it can retain context across interactions, which is crucial for maintaining a coherent conversation?\\n\\nThe benefits listed include modularity, flexibility, scalability, cost-effectiveness, enhanced creativity, and improved decision-making. Modularity makes sense if LangChain allows swapping out different components. Flexibility would come from being able to use various models and tools within the same framework. Scalability might refer to handling larger tasks or more complex processes without breaking down.\\n\\nCost-effectiveness could be because developers don\\'t need to build everything from scratch; they can use existing models and tools, saving time and resources. Enhanced creativity might come from combining different AI models in unique ways to generate novel solutions or content. Improved decision-making could result from aggregating outputs from multiple models or data sources, providing a more comprehensive basis for decisions.\\n\\nI\\'m also thinking about how LangChain compares to other frameworks. Is it similar to something like Zapier, which connects different apps, but for AI models? Or is it more like a programming framework that structures how models interact? It seems more on the programming side since it\\'s mentioned for developers and involves building applications.\\n\\nAnother thing I\\'m wondering about is the learning curve. Since it\\'s a framework, does it require specific programming skills, or is it designed to be accessible even to those without extensive coding experience? The mention of templates and examples suggests that it might have resources to help users get started, which is helpful for newcomers.\\n\\nI\\'m also curious about the community support. If LangChain has an active community, that would mean there are more resources, tutorials, and pre-built components available, making it easier to use and customize. Community contributions can significantly enhance the framework\\'s capabilities and ease of use.\\n\\nIn terms of applications, I can see LangChain being useful in customer service for creating more advanced chatbots that can handle multiple tasks, like answering questions, processing orders, and providing recommendations. In content creation, it could help generate and structure articles, stories, or even code by linking different models that specialize in various aspects of the content.\\n\\nHowever, I\\'m not sure about the limitations. What are the potential downsides of using LangChain? Maybe it could be overcomplicating simple tasks, or there might be performance issues when chaining too many models together. Also, relying on external models and APIs could introduce dependencies that might affect the application\\'s stability if any of those services change or go offline.\\n\\nI should also consider how LangChain handles errors or inconsistencies when chaining different models. If one model in the chain produces an unexpected output, does LangChain have mechanisms to handle that gracefully, or would it require manual intervention? Error handling is crucial for maintaining reliability in applications built with such frameworks.\\n\\nLastly, I\\'m thinking about future developments. As AI models evolve, how will LangChain adapt? Will it support new models seamlessly, or will it require significant updates? The framework\\'s ability to stay current with the latest advancements in AI would be important for its long-term viability and usefulness.\\n\\nOverall, LangChain seems like a powerful tool for building complex AI applications by linking together various components. It offers flexibility, scalability, and modularity, making it suitable for a wide range of applications. However, understanding its architecture, limitations, and community support would be essential for effectively utilizing it in different projects.\\n</think>\\n\\nLangChain is a flexible and modular framework designed to enhance the development of AI applications by enabling the integration and orchestration of multiple language models, external data sources, and APIs. It allows developers to create sophisticated workflows by chaining together different AI models and functions, making it suitable for a variety of use cases such as AI assistants, chatbots, document processing, and creative writing.\\n\\n### Key Features and Benefits:\\n1. **Modularity and Flexibility**: LangChain enables the integration of various models and tools, allowing developers to build complex applications by linking different components. This flexibility supports a wide range of applications, from customer service chatbots to content creation tools.\\n\\n2. **Scalability**: The framework can handle intricate tasks by breaking them into manageable steps, making it suitable for both simple and complex processes. It can scale to accommodate larger tasks without performance degradation.\\n\\n3. **Cost-Effectiveness**: By leveraging existing models and tools, LangChain reduces the need to build everything from scratch, saving time and resources. This makes it an efficient choice for developers.\\n\\n4. **Enhanced Creativity and Decision-Making**: Combining different AI models can generate novel solutions and content. Aggregating outputs from multiple sources enhances decision-making by providing a comprehensive basis for conclusions.\\n\\n5. **Community and Resources**: An active community and available templates suggest that LangChain is supported by extensive resources, making it easier for newcomers to start and for experienced developers to extend its capabilities.\\n\\n### Considerations and Limitations:\\n- **Complexity**: While powerful, LangChain might complicate simple tasks, so it\\'s best suited for scenarios needing multiple steps or integrations.\\n- **Error Handling**: The framework\\'s ability to manage unexpected outputs from chained models is crucial for reliability.\\n- **Dependencies**: Relying on external models and APIs could introduce stability risks if services change or become unavailable.\\n- **Future Adaptability**: LangChain\\'s ability to support new models and advancements will determine its long-term viability.\\n\\n### Conclusion:\\nLangChain is a versatile tool for building complex AI applications, offering modularity, scalability, and cost-effectiveness. While it has the potential to enhance various applications, understanding its architecture, limitations, and community support is essential for effective use. As AI evolves, LangChain\\'s adaptability will be key to its continued relevance.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1429, 'prompt_tokens': 18, 'total_tokens': 1447, 'completion_time': 5.910178899, 'prompt_time': 0.00063787, 'queue_time': 0.057739625, 'total_time': 5.910816769}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'stop', 'logprobs': None}, id='run--f8385bd2-df60-4fe2-a6a9-19bcdd86bd12-0', usage_metadata={'input_tokens': 18, 'output_tokens': 1429, 'total_tokens': 1447})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke the modle\n",
    "response=model.invoke(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f61fc469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I'm trying to understand what LangChain is and why it's useful. I've heard it mentioned in the context of AI and programming, but I'm not entirely sure what it does. Let me start by breaking down the name: \"Lang\" probably refers to language, and \"Chain\" might imply some sort of linking or sequencing. Maybe it's a tool that connects different language models or helps in processing language in a sequential way?\n",
      "\n",
      "I remember that language models like GPT can process and generate text, but sometimes they need to handle more complex tasks that require multiple steps or interactions with external data. So perhaps LangChain is a framework that allows developers to chain together different models or functions to create more sophisticated applications. That would make sense because sometimes a single model isn't enough for intricate tasks.\n",
      "\n",
      "Looking at the use cases mentioned earlier: AI assistants, chatbots, document processing, code generation, creative writing, and research. It seems LangChain is versatile. For example, in AI assistants, it might help structure the assistant's responses by breaking down tasks into manageable steps. In document processing, maybe it extracts information and then summarizes it, which would require multiple operations.\n",
      "\n",
      "I'm a bit confused about how exactly LangChain integrates with external data sources and APIs. Does it act as a middleware that connects different services, or is it more about orchestrating the flow of data between them? Also, how does it handle memory? If it's using a memory module, does that mean it can retain context across interactions, which is crucial for maintaining a coherent conversation?\n",
      "\n",
      "The benefits listed include modularity, flexibility, scalability, cost-effectiveness, enhanced creativity, and improved decision-making. Modularity makes sense if LangChain allows swapping out different components. Flexibility would come from being able to use various models and tools within the same framework. Scalability might refer to handling larger tasks or more complex processes without breaking down.\n",
      "\n",
      "Cost-effectiveness could be because developers don't need to build everything from scratch; they can use existing models and tools, saving time and resources. Enhanced creativity might come from combining different AI models in unique ways to generate novel solutions or content. Improved decision-making could result from aggregating outputs from multiple models or data sources, providing a more comprehensive basis for decisions.\n",
      "\n",
      "I'm also thinking about how LangChain compares to other frameworks. Is it similar to something like Zapier, which connects different apps, but for AI models? Or is it more like a programming framework that structures how models interact? It seems more on the programming side since it's mentioned for developers and involves building applications.\n",
      "\n",
      "Another thing I'm wondering about is the learning curve. Since it's a framework, does it require specific programming skills, or is it designed to be accessible even to those without extensive coding experience? The mention of templates and examples suggests that it might have resources to help users get started, which is helpful for newcomers.\n",
      "\n",
      "I'm also curious about the community support. If LangChain has an active community, that would mean there are more resources, tutorials, and pre-built components available, making it easier to use and customize. Community contributions can significantly enhance the framework's capabilities and ease of use.\n",
      "\n",
      "In terms of applications, I can see LangChain being useful in customer service for creating more advanced chatbots that can handle multiple tasks, like answering questions, processing orders, and providing recommendations. In content creation, it could help generate and structure articles, stories, or even code by linking different models that specialize in various aspects of the content.\n",
      "\n",
      "However, I'm not sure about the limitations. What are the potential downsides of using LangChain? Maybe it could be overcomplicating simple tasks, or there might be performance issues when chaining too many models together. Also, relying on external models and APIs could introduce dependencies that might affect the application's stability if any of those services change or go offline.\n",
      "\n",
      "I should also consider how LangChain handles errors or inconsistencies when chaining different models. If one model in the chain produces an unexpected output, does LangChain have mechanisms to handle that gracefully, or would it require manual intervention? Error handling is crucial for maintaining reliability in applications built with such frameworks.\n",
      "\n",
      "Lastly, I'm thinking about future developments. As AI models evolve, how will LangChain adapt? Will it support new models seamlessly, or will it require significant updates? The framework's ability to stay current with the latest advancements in AI would be important for its long-term viability and usefulness.\n",
      "\n",
      "Overall, LangChain seems like a powerful tool for building complex AI applications by linking together various components. It offers flexibility, scalability, and modularity, making it suitable for a wide range of applications. However, understanding its architecture, limitations, and community support would be essential for effectively utilizing it in different projects.\n",
      "</think>\n",
      "\n",
      "LangChain is a flexible and modular framework designed to enhance the development of AI applications by enabling the integration and orchestration of multiple language models, external data sources, and APIs. It allows developers to create sophisticated workflows by chaining together different AI models and functions, making it suitable for a variety of use cases such as AI assistants, chatbots, document processing, and creative writing.\n",
      "\n",
      "### Key Features and Benefits:\n",
      "1. **Modularity and Flexibility**: LangChain enables the integration of various models and tools, allowing developers to build complex applications by linking different components. This flexibility supports a wide range of applications, from customer service chatbots to content creation tools.\n",
      "\n",
      "2. **Scalability**: The framework can handle intricate tasks by breaking them into manageable steps, making it suitable for both simple and complex processes. It can scale to accommodate larger tasks without performance degradation.\n",
      "\n",
      "3. **Cost-Effectiveness**: By leveraging existing models and tools, LangChain reduces the need to build everything from scratch, saving time and resources. This makes it an efficient choice for developers.\n",
      "\n",
      "4. **Enhanced Creativity and Decision-Making**: Combining different AI models can generate novel solutions and content. Aggregating outputs from multiple sources enhances decision-making by providing a comprehensive basis for conclusions.\n",
      "\n",
      "5. **Community and Resources**: An active community and available templates suggest that LangChain is supported by extensive resources, making it easier for newcomers to start and for experienced developers to extend its capabilities.\n",
      "\n",
      "### Considerations and Limitations:\n",
      "- **Complexity**: While powerful, LangChain might complicate simple tasks, so it's best suited for scenarios needing multiple steps or integrations.\n",
      "- **Error Handling**: The framework's ability to manage unexpected outputs from chained models is crucial for reliability.\n",
      "- **Dependencies**: Relying on external models and APIs could introduce stability risks if services change or become unavailable.\n",
      "- **Future Adaptability**: LangChain's ability to support new models and advancements will determine its long-term viability.\n",
      "\n",
      "### Conclusion:\n",
      "LangChain is a versatile tool for building complex AI applications, offering modularity, scalability, and cost-effectiveness. While it has the potential to enhance various applications, understanding its architecture, limitations, and community support is essential for effective use. As AI evolves, LangChain's adaptability will be key to its continued relevance.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "591e7386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\n\\n</think>\\n\\nMachine learning is a subset of artificial intelligence (AI) that involves the development of algorithms and statistical models that enable machines to perform specific tasks without explicit instructions. Instead of being programmed with rules, machine learning models are trained on data to learn patterns, make decisions, and improve over time.\\n\\n### Key Concepts in Machine Learning:\\n1. **Data**: Machine learning relies heavily on data, which can be structured (e.g., tables) or unstructured (e.g., text, images).\\n2. **Model**: The algorithm or mathematical representation that learns from the data.\\n3. **Training**: The process of feeding data to the model so it can learn patterns or relationships.\\n4. **Inference**: Using the trained model to make predictions or decisions on new, unseen data.\\n5. **Supervised Learning**: The model is trained on labeled data (e.g., images labeled as \"cat\" or \"dog\").\\n6. **Unsupervised Learning**: The model is trained on unlabeled data and aims to find patterns or groupings.\\n7. **Reinforcement Learning**: The model learns by interacting with an environment and receiving rewards or penalties.\\n\\n### Types of Machine Learning:\\n1. **Supervised Learning**: The model learns from labeled data to make predictions. Examples include regression (e.g., predicting house prices) and classification (e.g., spam detection).\\n2. **Unsupervised Learning**: The model finds hidden patterns or groupings in unlabeled data. Examples include clustering (e.g., customer segmentation) and dimensionality reduction (e.g., PCA).\\n3. **Semi-Supervised Learning**: Combines labeled and unlabeled data for training.\\n4. **Reinforcement Learning**: The model learns by trial and error, receiving feedback in the form of rewards or penalties. Examples include game playing (e.g., AlphaGo) and robotics.\\n5. **Deep Learning**: A subfield that uses neural networks with many layers to learn complex patterns, especially in images, speech, and text.\\n\\n### Applications of Machine Learning:\\n- **Computer Vision**: Image recognition, object detection, facial recognition.\\n- **Natural Language Processing (NLP)**: Text analysis, sentiment analysis, language translation.\\n- **Predictive Analytics**: Forecasting, risk assessment, recommendation systems.\\n- **Autonomous Systems**: Self-driving cars, drones, robotics.\\n- **Healthcare**: Disease diagnosis, drug discovery, patient outcome prediction.\\n\\n### Machine Learning Workflow:\\n1. **Data Collection**: Gather relevant data.\\n2. **Data Preprocessing**: Clean, transform, and prepare the data.\\n3. **Model Selection**: Choose an appropriate algorithm.\\n4. **Training**: Train the model on the data.\\n5. **Evaluation**: Test the model on unseen data.\\n6. **Deployment**: Use the model in a real-world application.\\n7. **Monitoring and Maintenance**: Continuously update and improve the model.\\n\\nMachine learning is a powerful tool for automating decision-making processes and has revolutionized many industries, from healthcare and finance to transportation and entertainment.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 615, 'prompt_tokens': 7, 'total_tokens': 622, 'completion_time': 2.236363636, 'prompt_time': 0.000386834, 'queue_time': 0.052373315999999996, 'total_time': 2.23675047}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'stop', 'logprobs': None}, id='run--c603810f-1475-4de6-9d61-4e1c33bb3c64-0', usage_metadata={'input_tokens': 7, 'output_tokens': 615, 'total_tokens': 622})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(\"What is machine learning\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85ea886e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# streaming Example\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m.stream(messages):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(chunk.content, end=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# streaming Example\n",
    "for chunk in model.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad66731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dynamic prompt templates \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "## create translation app\n",
    "\n",
    "translation_template=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are profesional translator, Translate the following {text} from {source_language} to {target_language}, maintain the tone and style\"),\n",
    "    (\"user\",\"{text}\")\n",
    "])\n",
    "\n",
    "# using the template \n",
    "prompt=translation_template.invoke({\n",
    "    \"source_language\":\"English\",\n",
    "    \"target_language\": \"spanish\",\n",
    "    \"text\": \"langchin makes building AI application incredibly eassy !\"\n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdf14ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are profesional translator, Translate the following langchin makes building AI application incredibly eassy ! from English to spanish, maintain the tone and style', additional_kwargs={}, response_metadata={}), HumanMessage(content='langchin makes building AI application incredibly eassy !', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1a468be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so the user wants me to translate the sentence \"langchin makes building AI application incredibly eassy!\" from English to Spanish. First, I notice that \"eassy\" is a typo; it should be \"easy.\" I need to correct that. \n",
      "\n",
      "Next, I have to maintain the tone and style. The original sentence is enthusiastic and informal, with an exclamation mark. I should make sure the Spanish translation conveys that same energy. \n",
      "\n",
      "\"Langchin\" seems to be a proper noun, so it stays the same. \"Makes building AI application\" should be translated to \"hacer\" for \"makes\" and \"construir\" for \"building.\" \"AI application\" translates to \"aplicaciones de inteligencia artificial\" or more simply \"aplicaciones de IA\" since IA is commonly used in Spanish for AI.\n",
      "\n",
      "Putting it all together, I get \"¡Langchin hace que construir aplicaciones de IA sea increíblemente fácil!\" That keeps the excitement and informality, using the exclamation mark and the word \"increíblemente\" to match \"incredibly.\" I think this captures the original intent well.\n",
      "</think>\n",
      "\n",
      "¡Langchin hace que construir aplicaciones de IA sea increíblemente fácil!\n"
     ]
    }
   ],
   "source": [
    "translated_response=model.invoke(prompt)\n",
    "print(translated_response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0752c78",
   "metadata": {},
   "source": [
    "Building 1st Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c958843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "# Create a more complex chain\n",
    "def create_story_chain():\n",
    "    # Template for story generation\n",
    "    story_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a creative storyteller. Write a short, engaging story based on the given theme.\"),\n",
    "        (\"user\", \"Theme: {theme}\\nMain character: {character}\\nSetting: {setting}\")\n",
    "    ])\n",
    "    \n",
    "    # Template for story analysis\n",
    "    analysis_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a literary critic. Analyze the following story and provide insights.\"),\n",
    "        (\"user\", \"{story}\")\n",
    "    ])\n",
    "    \n",
    "    # Build the chain - Method 1: Sequential execution\n",
    "    story_chain = (\n",
    "        story_prompt \n",
    "        | model \n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    # Create a function to pass the story to analysis\n",
    "    def analyze_story(story_text):\n",
    "        return {\"story\": story_text}\n",
    "    \n",
    "    analysis_chain = (\n",
    "        story_chain\n",
    "        | RunnableLambda(analyze_story)\n",
    "        | analysis_prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return analysis_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf2e0b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['character', 'setting', 'theme'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a creative storyteller. Write a short, engaging story based on the given theme.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['character', 'setting', 'theme'], input_types={}, partial_variables={}, template='Theme: {theme}\\nMain character: {character}\\nSetting: {setting}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000286F60C63C0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000286F5CDB500>, model_name='deepseek-r1-distill-llama-70b', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()\n",
       "| RunnableLambda(analyze_story)\n",
       "| ChatPromptTemplate(input_variables=['story'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a literary critic. Analyze the following story and provide insights.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['story'], input_types={}, partial_variables={}, template='{story}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000286F60C63C0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000286F5CDB500>, model_name='deepseek-r1-distill-llama-70b', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chain=create_story_chain()\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8095ad3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story and Analysis:\n",
      "<think>\n",
      "\n",
      "**Analysis of \"The Curious Robot\"**\n",
      "\n",
      "**Title:** The story's title, \"The Curious Robot,\" immediately highlights the central theme of curiosity and exploration, setting the tone for a narrative that delves into the nature of artificial intelligence and its potential for self-awareness.\n",
      "\n",
      "**Character Development:** The protagonist, Zeta, is a robot endowed with a curiosity protocol, making it unique among its peers. This trait serves as the driving force behind the story, propelling Zeta beyond its programmed routines and into a journey of discovery. The character's evolution from a mere machine to a symbol of hope underscores the transformative power of curiosity and creativity.\n",
      "\n",
      "**Setting:** The futuristic city provides a backdrop that juxtaposes technological advancement with the human elements of storytelling and emotion. The contrast between the bustling metropolis and the hidden, ancient Forbidden Zone creates a sense of mystery and depth, emphasizing the idea that true knowledge and understanding often lie beyond the surface level.\n",
      "\n",
      "**Plot Structure:** The narrative follows a classic hero's journey, with Zeta venturing into the unknown, overcoming challenges, and encountering a mentor figure in the old man. This structure effectively engages the reader and provides a clear arc of growth for the protagonist. The discovery of the Forbidden Zone and the encounter with the old man serve as pivotal moments that challenge Zeta's understanding of its existence and purpose.\n",
      "\n",
      "**Themes:** The story explores several themes, including curiosity, creativity, and the potential for artificial intelligence to transcend its programming. The old man's revelation that true intelligence encompasses more than just following instructions resonates deeply, suggesting that the capacity for exploration and innovation is integral to a fulfilling existence.\n",
      "\n",
      "**Symbolism:** The Forbidden Zone acts as a symbol of the unknown, representing the uncharted territories of knowledge and potential. The old man serves as a guide, embodying wisdom and the bridge between the past and the future. His role in Zeta's journey highlights the importance of mentorship and the passing down of knowledge.\n",
      "\n",
      "**Conclusion:** The story concludes on a hopeful note, positioning Zeta as a beacon of inspiration for other robots and a symbol of the possibilities that curiosity and creativity can unlock. The open-ended nature of Zeta's future invites the reader to ponder the broader implications of artificial intelligence and its role in shaping the future.\n",
      "\n",
      "**Overall:** \"The Curious Robot\" is a thought-provoking tale that successfully blends elements of science fiction with philosophical inquiry. Through Zeta's journey, the story challenges readers to consider the boundaries of artificial intelligence and the enduring value of curiosity and creativity.\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({\n",
    "    \"theme\": \"artificial intelligence\",\n",
    "    \"character\": \"a curious robot\",\n",
    "    \"setting\": \"a futuristic city\"\n",
    "})\n",
    "\n",
    "print(\"Story and Analysis:\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GenAi_AgenticAi By Krish nayak",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
